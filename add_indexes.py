#!/usr/bin/env python3
"""
Performance Optimization Script for FIMS
Run this script once to add database indexes that significantly improve query performance.

Usage:
    python add_indexes.py

This script will:
1. Connect to your database (Turso cloud or local SQLite)
2. Create indexes on frequently queried columns
3. Dramatically speed up JOIN and WHERE clause operations
"""

import os
import sys

def main():
    print("=" * 60)
    print("FIMS Database Index Optimization Script")
    print("=" * 60)
    
    # Try to connect to database
    conn = None
    db_type = "unknown"
    
    # Check for Turso cloud database
    turso_url = os.environ.get('TURSO_DATABASE_URL')
    turso_token = os.environ.get('TURSO_AUTH_TOKEN')
    
    if turso_url and turso_token:
        try:
            import libsql_experimental as libsql
            conn = libsql.connect(turso_url, auth_token=turso_token)
            db_type = "Turso Cloud"
            print(f"âœ… Connected to {db_type} database")
        except ImportError:
            print("âš ï¸ libsql_experimental not installed. Trying local SQLite...")
        except Exception as e:
            print(f"âš ï¸ Failed to connect to Turso: {e}")
    
    # Fall back to local SQLite
    if conn is None:
        try:
            import sqlite3
            db_path = os.path.join(os.path.dirname(__file__), 'fims.db')
            if os.path.exists(db_path):
                conn = sqlite3.connect(db_path)
                db_type = "Local SQLite"
                print(f"âœ… Connected to {db_type} database: {db_path}")
            else:
                print(f"âŒ Local database not found at: {db_path}")
                sys.exit(1)
        except Exception as e:
            print(f"âŒ Failed to connect to local database: {e}")
            sys.exit(1)
    
    cursor = conn.cursor()
    
    # Define indexes to create
    # Format: (index_name, table, columns, description)
    indexes = [
        # Loading Slips indexes - most critical for N+1 queries
        ("idx_loading_slips_rake_code", "loading_slips", "rake_code", 
         "Speeds up rake balance calculations"),
        ("idx_loading_slips_account_id", "loading_slips", "account_id",
         "Speeds up account dispatch lookups"),
        ("idx_loading_slips_warehouse_id", "loading_slips", "warehouse_id",
         "Speeds up warehouse dispatch lookups"),
        ("idx_loading_slips_cgmf_id", "loading_slips", "cgmf_id",
         "Speeds up CGMF dispatch lookups"),
        
        # Builty indexes
        ("idx_builty_rake_code", "builty", "rake_code",
         "Speeds up builty-rake joins"),
        ("idx_builty_account_id", "builty", "account_id",
         "Speeds up builty-account joins"),
        ("idx_builty_warehouse_id", "builty", "warehouse_id",
         "Speeds up builty-warehouse joins"),
        ("idx_builty_created_by_role", "builty", "created_by_role",
         "Speeds up role-based filtering"),
        
        # Warehouse stock indexes
        ("idx_warehouse_stock_warehouse_id", "warehouse_stock", "warehouse_id",
         "Speeds up warehouse balance calculations"),
        ("idx_warehouse_stock_builty_id", "warehouse_stock", "builty_id",
         "Speeds up builty-stock joins"),
        ("idx_warehouse_stock_transaction_type", "warehouse_stock", "transaction_type",
         "Speeds up IN/OUT filtering"),
        ("idx_warehouse_stock_date", "warehouse_stock", "date",
         "Speeds up date-based queries"),
        ("idx_warehouse_stock_account_id", "warehouse_stock", "account_id",
         "Speeds up account stock lookups"),
        
        # Rake indexes
        ("idx_rakes_is_closed", "rakes", "is_closed",
         "Speeds up active rake filtering"),
        ("idx_rakes_company_name", "rakes", "company_name",
         "Speeds up company filtering"),
        
        # E-bills indexes
        ("idx_ebills_builty_id", "ebills", "builty_id",
         "Speeds up ebill-builty joins"),
        
        # Rake bill payments
        ("idx_rake_bill_payments_rake_code", "rake_bill_payments", "rake_code",
         "Speeds up payment lookups"),
    ]
    
    print(f"\nğŸ“Š Creating {len(indexes)} performance indexes...\n")
    
    success_count = 0
    skip_count = 0
    fail_count = 0
    
    for idx_name, table, columns, description in indexes:
        sql = f"CREATE INDEX IF NOT EXISTS {idx_name} ON {table}({columns})"
        try:
            cursor.execute(sql)
            print(f"  âœ… {idx_name}")
            print(f"     â””â”€ {description}")
            success_count += 1
        except Exception as e:
            error_str = str(e).lower()
            if "already exists" in error_str:
                print(f"  â­ï¸  {idx_name} (already exists)")
                skip_count += 1
            elif "no such table" in error_str:
                print(f"  âš ï¸  {idx_name} - Table '{table}' doesn't exist yet")
                skip_count += 1
            else:
                print(f"  âŒ {idx_name} - Error: {e}")
                fail_count += 1
    
    # Commit changes
    try:
        conn.commit()
        print("\nâœ… Changes committed to database")
    except Exception as e:
        print(f"\nâš ï¸ Commit note: {e}")
    
    # Print summary
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"  âœ… Created: {success_count}")
    print(f"  â­ï¸  Skipped: {skip_count}")
    print(f"  âŒ Failed:  {fail_count}")
    print()
    
    if success_count > 0:
        print("ğŸš€ Database indexes have been optimized!")
        print("   Expected performance improvement: 50-90% faster queries")
        print()
    
    # Additional optimization: ANALYZE
    print("ğŸ“ˆ Running ANALYZE to update query optimizer statistics...")
    try:
        cursor.execute("ANALYZE")
        conn.commit()
        print("  âœ… ANALYZE complete")
    except Exception as e:
        print(f"  âš ï¸ ANALYZE note: {e}")
    
    print("\nâœ… Optimization complete!")
    print("   Your database is now optimized for faster queries.")


if __name__ == '__main__':
    main()
